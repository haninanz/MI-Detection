{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectA-160405-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     850.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "959 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectA-160408-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "867 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectB-151110-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     850.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "958 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectB-160309-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "935 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectB-160311-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "959 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectB-160316-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     850.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "959 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectC-151204-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     850.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "958 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectC-160429-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "941 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectE-160321-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "956 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectE-160415-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "946 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectE-160429-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "946 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectF-151027-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     850.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "957 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectF-160209-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     850.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "958 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectF-160210-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "959 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectG-160413-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "946 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectG-160428-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "955 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectH-160804-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "922 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectI-160719-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "959 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\hanin\\Documents\\Kuliah\\Semester 7\\Tugas Akhir\\Preprocessed Data MI\\Epoch\\SubjectI-160723-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...     845.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "958 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'Preprocessed Data MI'\n",
    "epoch_data_path = os.path.join(os.getcwd(), data_dir + '\\Epoch')\n",
    "dirs = os.listdir(os.path.join(os.getcwd(), 'Dataset Motor Imagery'))\n",
    "eeg_data = [mne.read_epochs(os.path.join(epoch_data_path, epoch_file)) for epoch_file in os.listdir(epoch_data_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data = []\n",
    "epoch_label = []\n",
    "subject_last_index = []\n",
    "# scaler = StandardScaler()\n",
    "for i in range(len(eeg_data)):\n",
    "    eeg_data[i] = eeg_data[i].crop(tmin = 0, tmax = 0.845, include_tmax = True)\n",
    "    for epoch in eeg_data[i].get_data():\n",
    "#         epoch = scaler.fit_transform(epoch)\n",
    "        epoch_data.append(np.reshape(epoch, newshape = (epoch.shape[0], epoch.shape[1], 1)))\n",
    "    for event in eeg_data[i].events:\n",
    "        epoch_label.append(event[2] - 1)\n",
    "    subject_last_index.append((dirs[i].split('-')[1], len(epoch_data) - 1))\n",
    "epoch_data = np.asarray(epoch_data, dtype = np.float32)\n",
    "epoch_label = np.asarray(epoch_label, dtype = np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (17998, 21, 170, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Data shape: {}'.format(epoch_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SubjectA': 1825,\n",
       " 'SubjectB': 5636,\n",
       " 'SubjectC': 7535,\n",
       " 'SubjectE': 10383,\n",
       " 'SubjectF': 13257,\n",
       " 'SubjectG': 15158,\n",
       " 'SubjectH': 16080,\n",
       " 'SubjectI': 17997}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_index = {}\n",
    "for subject, last_index in subject_last_index:\n",
    "    if subject not in subject_index:\n",
    "        subject_index[subject] = last_index\n",
    "    if last_index > subject_index[subject]:\n",
    "        subject_index[subject] = last_index\n",
    "subject_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(subject_name):\n",
    "    index_list = list(subject_index.values())\n",
    "    subj_idx = list(subject_index.keys()).index(subject_name)\n",
    "    if subj_idx - 1 < 0:\n",
    "        data_index = list(range(index_list[subj_idx]))\n",
    "    else:\n",
    "        data_index = list(range(index_list[subj_idx - 1], index_list[subj_idx]))\n",
    "    return epoch_data[data_index], epoch_label[data_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(data, new_data_len, data_gap):\n",
    "    new_data_indices = []\n",
    "    data_len = len(data)\n",
    "    data_start_index, data_end_index = 0, new_data_len\n",
    "    while data_end_index <= data_len:\n",
    "        new_data_indices.append(list(range(data_start_index, data_end_index)))\n",
    "        data_start_index += data_gap\n",
    "        data_end_index += data_gap\n",
    "    new_data = [data[data_indices] for data_indices in new_data_indices]\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name = 'SubjectB'\n",
    "data, labels = retrieve_data(subject_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length, data_gap = 150, 10\n",
    "copy_data = data.copy()\n",
    "epoch_data, epoch_label = [], []\n",
    "for index, data in enumerate(copy_data):\n",
    "    augmented_data = []\n",
    "    for channel_index in range(data.shape[0]):\n",
    "        augmented_data.append(sliding_window(data[channel_index, :, 0], data_length, data_gap))\n",
    "    augmented_data = np.array(augmented_data)\n",
    "    for data_index in range(augmented_data.shape[1]):\n",
    "        new_data = augmented_data[:, data_index]\n",
    "        new_label = labels[index]\n",
    "        epoch_data.append(new_data)\n",
    "        epoch_label.append(new_label)\n",
    "epoch_data = np.array(epoch_data)\n",
    "epoch_label = np.array(epoch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(epoch_data.shape[0])\n",
    "np.random.shuffle(shuffled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data = epoch_data[shuffled_indices]\n",
    "epoch_label = epoch_label[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(input_shape, optimizer = None):\n",
    "    conv1_init = tf.keras.initializers.GlorotUniform(42)\n",
    "    conv2_init = tf.keras.initializers.GlorotUniform(42)\n",
    "    dense1_init = tf.keras.initializers.GlorotUniform(24)\n",
    "    dense2_init = tf.keras.initializers.GlorotUniform(24)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters = 64, kernel_size = (1, 5), padding = 'same', input_shape = input_shape,\n",
    "                               activation = 'relu', kernel_initializer = conv1_init),\n",
    "        tf.keras.layers.Conv2D(filters = 64, kernel_size = (input_shape[0], 1), activation = 'relu',\n",
    "                               kernel_initializer = conv2_init),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size = (1, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(units = 32, activation = 'elu', kernel_initializer = dense1_init),\n",
    "        tf.keras.layers.Dense(units = 5, activation = 'softmax', kernel_initializer = dense2_init)\n",
    "    ])\n",
    "    if optimizer is None:\n",
    "        model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(5 * 1e-5),\n",
    "                      metrics = ['accuracy'])\n",
    "    else:\n",
    "        model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_kfold = StratifiedKFold(n_splits = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, acc_scores = [], []\n",
    "prec_scores, rec_scores = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "644/644 [==============================] - 35s 55ms/step - loss: 1.5264 - accuracy: 0.3080 - val_loss: 1.4393 - val_accuracy: 0.3628\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 41s 64ms/step - loss: 1.3701 - accuracy: 0.4143 - val_loss: 1.4277 - val_accuracy: 0.3741\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 43s 66ms/step - loss: 1.2830 - accuracy: 0.4577 - val_loss: 1.3078 - val_accuracy: 0.4467\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 42s 66ms/step - loss: 1.2181 - accuracy: 0.4974 - val_loss: 1.2887 - val_accuracy: 0.4467\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 42s 66ms/step - loss: 1.1552 - accuracy: 0.5242 - val_loss: 1.2558 - val_accuracy: 0.4790\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 42s 66ms/step - loss: 1.0991 - accuracy: 0.5560 - val_loss: 1.2595 - val_accuracy: 0.4808\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 43s 67ms/step - loss: 1.0490 - accuracy: 0.5815 - val_loss: 1.3327 - val_accuracy: 0.4615\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 43s 67ms/step - loss: 0.9936 - accuracy: 0.6040 - val_loss: 1.2810 - val_accuracy: 0.4808\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 44s 69ms/step - loss: 0.9388 - accuracy: 0.6315 - val_loss: 1.2605 - val_accuracy: 0.4939\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 45s 70ms/step - loss: 0.8892 - accuracy: 0.6550 - val_loss: 1.2673 - val_accuracy: 0.4974\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 46s 72ms/step - loss: 0.8389 - accuracy: 0.6818 - val_loss: 1.2642 - val_accuracy: 0.4921\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 47s 73ms/step - loss: 0.7854 - accuracy: 0.7035 - val_loss: 1.3332 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 48s 75ms/step - loss: 0.7387 - accuracy: 0.7241 - val_loss: 1.3053 - val_accuracy: 0.4878\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 49s 76ms/step - loss: 0.6840 - accuracy: 0.7485 - val_loss: 1.3327 - val_accuracy: 0.5070\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 48s 74ms/step - loss: 0.6367 - accuracy: 0.7720 - val_loss: 1.3431 - val_accuracy: 0.5026\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 52s 80ms/step - loss: 0.5900 - accuracy: 0.7925 - val_loss: 1.3844 - val_accuracy: 0.5035\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 58s 90ms/step - loss: 0.5461 - accuracy: 0.8092 - val_loss: 1.4480 - val_accuracy: 0.4991\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 61s 95ms/step - loss: 0.5017 - accuracy: 0.8333 - val_loss: 1.4592 - val_accuracy: 0.4886\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 35s 55ms/step - loss: 0.4586 - accuracy: 0.8481 - val_loss: 1.5184 - val_accuracy: 0.5026\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 53s 83ms/step - loss: 0.4101 - accuracy: 0.8714 - val_loss: 1.6004 - val_accuracy: 0.4956\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 51s 79ms/step - loss: 0.3761 - accuracy: 0.8856 - val_loss: 1.6349 - val_accuracy: 0.4904\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 47s 73ms/step - loss: 0.3344 - accuracy: 0.9014 - val_loss: 1.6712 - val_accuracy: 0.5009\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 52s 81ms/step - loss: 0.3064 - accuracy: 0.9107 - val_loss: 1.7234 - val_accuracy: 0.4930\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 54s 84ms/step - loss: 0.2679 - accuracy: 0.9260 - val_loss: 1.7978 - val_accuracy: 0.4930\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.2378 - accuracy: 0.9375 - val_loss: 1.9297 - val_accuracy: 0.4921\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 49s 77ms/step - loss: 0.2096 - accuracy: 0.9490 - val_loss: 1.9253 - val_accuracy: 0.4956\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 52s 81ms/step - loss: 0.1847 - accuracy: 0.9588 - val_loss: 2.0465 - val_accuracy: 0.4939\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 48s 75ms/step - loss: 0.1604 - accuracy: 0.9669 - val_loss: 2.0633 - val_accuracy: 0.4921\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.1362 - accuracy: 0.9746 - val_loss: 2.1618 - val_accuracy: 0.4974\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 36s 56ms/step - loss: 0.1120 - accuracy: 0.9834 - val_loss: 2.2991 - val_accuracy: 0.4878\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 2.2991 - accuracy: 0.4878\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 48s 75ms/step - loss: 1.5278 - accuracy: 0.3128 - val_loss: 1.4616 - val_accuracy: 0.3636\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 50s 77ms/step - loss: 1.3617 - accuracy: 0.4122 - val_loss: 1.3749 - val_accuracy: 0.4056\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 1.2683 - accuracy: 0.4678 - val_loss: 1.3595 - val_accuracy: 0.4274\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 48s 75ms/step - loss: 1.1910 - accuracy: 0.5121 - val_loss: 1.3245 - val_accuracy: 0.4502\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 52s 80ms/step - loss: 1.1292 - accuracy: 0.5449 - val_loss: 1.3113 - val_accuracy: 0.4467\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 1.0639 - accuracy: 0.5821 - val_loss: 1.3126 - val_accuracy: 0.4572\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 51s 79ms/step - loss: 1.0059 - accuracy: 0.6083 - val_loss: 1.3232 - val_accuracy: 0.4484\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 54s 84ms/step - loss: 0.9534 - accuracy: 0.6317 - val_loss: 1.3380 - val_accuracy: 0.4580\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 49s 76ms/step - loss: 0.8949 - accuracy: 0.6575 - val_loss: 1.3311 - val_accuracy: 0.4712\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 55s 85ms/step - loss: 0.8411 - accuracy: 0.6861 - val_loss: 1.3464 - val_accuracy: 0.4729\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 51s 79ms/step - loss: 0.7899 - accuracy: 0.7102 - val_loss: 1.3334 - val_accuracy: 0.4703\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.7406 - accuracy: 0.7300 - val_loss: 1.3571 - val_accuracy: 0.4729\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 52s 81ms/step - loss: 0.6846 - accuracy: 0.7495 - val_loss: 1.3660 - val_accuracy: 0.4781\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 46s 71ms/step - loss: 0.6363 - accuracy: 0.7784 - val_loss: 1.3967 - val_accuracy: 0.4650\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 46s 72ms/step - loss: 0.5880 - accuracy: 0.7974 - val_loss: 1.4058 - val_accuracy: 0.4624\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 49s 76ms/step - loss: 0.5430 - accuracy: 0.8132 - val_loss: 1.4644 - val_accuracy: 0.4729\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 44s 68ms/step - loss: 0.4999 - accuracy: 0.8327 - val_loss: 1.5339 - val_accuracy: 0.4825\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 47s 72ms/step - loss: 0.4551 - accuracy: 0.8530 - val_loss: 1.5319 - val_accuracy: 0.4825\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 41s 64ms/step - loss: 0.4117 - accuracy: 0.8675 - val_loss: 1.5721 - val_accuracy: 0.4685\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 44s 68ms/step - loss: 0.3715 - accuracy: 0.8868 - val_loss: 1.6057 - val_accuracy: 0.4720\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 36s 56ms/step - loss: 0.3372 - accuracy: 0.9019 - val_loss: 1.6667 - val_accuracy: 0.4878\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.2992 - accuracy: 0.9146 - val_loss: 1.7619 - val_accuracy: 0.4790\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 44s 68ms/step - loss: 0.2703 - accuracy: 0.9275 - val_loss: 1.8719 - val_accuracy: 0.4642\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 45s 70ms/step - loss: 0.2310 - accuracy: 0.9410 - val_loss: 1.9353 - val_accuracy: 0.4703\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 49s 75ms/step - loss: 0.2018 - accuracy: 0.9504 - val_loss: 1.9542 - val_accuracy: 0.4773\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 44s 68ms/step - loss: 0.1802 - accuracy: 0.9602 - val_loss: 2.0216 - val_accuracy: 0.4703\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/644 [==============================] - 45s 70ms/step - loss: 0.1574 - accuracy: 0.9673 - val_loss: 2.1467 - val_accuracy: 0.4589\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 48s 74ms/step - loss: 0.1290 - accuracy: 0.9750 - val_loss: 2.1908 - val_accuracy: 0.4869\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 44s 69ms/step - loss: 0.1065 - accuracy: 0.9844 - val_loss: 2.3139 - val_accuracy: 0.4738\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 46s 71ms/step - loss: 0.0936 - accuracy: 0.9872 - val_loss: 2.4383 - val_accuracy: 0.4642\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 2.4383 - accuracy: 0.4642\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 44s 68ms/step - loss: 1.5281 - accuracy: 0.3096 - val_loss: 1.4180 - val_accuracy: 0.3767\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 44s 68ms/step - loss: 1.3733 - accuracy: 0.4116 - val_loss: 1.3327 - val_accuracy: 0.4100\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 47s 73ms/step - loss: 1.2831 - accuracy: 0.4627 - val_loss: 1.3037 - val_accuracy: 0.4283\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 47s 73ms/step - loss: 1.2108 - accuracy: 0.5010 - val_loss: 1.2811 - val_accuracy: 0.4484\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.1434 - accuracy: 0.5359 - val_loss: 1.2523 - val_accuracy: 0.4615\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 45s 71ms/step - loss: 1.0837 - accuracy: 0.5699 - val_loss: 1.2547 - val_accuracy: 0.4633\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 47s 73ms/step - loss: 1.0219 - accuracy: 0.5976 - val_loss: 1.2354 - val_accuracy: 0.4659\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 44s 69ms/step - loss: 0.9666 - accuracy: 0.6273 - val_loss: 1.2369 - val_accuracy: 0.4764\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 45s 70ms/step - loss: 0.9099 - accuracy: 0.6518 - val_loss: 1.2367 - val_accuracy: 0.4781\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 48s 75ms/step - loss: 0.8539 - accuracy: 0.6742 - val_loss: 1.2392 - val_accuracy: 0.4790\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 43s 67ms/step - loss: 0.7997 - accuracy: 0.7049 - val_loss: 1.2501 - val_accuracy: 0.4956\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 45s 70ms/step - loss: 0.7466 - accuracy: 0.7268 - val_loss: 1.2981 - val_accuracy: 0.4694\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.6940 - accuracy: 0.7486 - val_loss: 1.3045 - val_accuracy: 0.4834\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 46s 71ms/step - loss: 0.6502 - accuracy: 0.7716 - val_loss: 1.3168 - val_accuracy: 0.4790\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 41s 64ms/step - loss: 0.6002 - accuracy: 0.7884 - val_loss: 1.3553 - val_accuracy: 0.4677\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 43s 66ms/step - loss: 0.5519 - accuracy: 0.8090 - val_loss: 1.4103 - val_accuracy: 0.4694\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 44s 68ms/step - loss: 0.5115 - accuracy: 0.8227 - val_loss: 1.4243 - val_accuracy: 0.4799\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 45s 70ms/step - loss: 0.4665 - accuracy: 0.8425 - val_loss: 1.4677 - val_accuracy: 0.4834\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 48s 74ms/step - loss: 0.4272 - accuracy: 0.8597 - val_loss: 1.4904 - val_accuracy: 0.4895\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 48s 74ms/step - loss: 0.3826 - accuracy: 0.8792 - val_loss: 1.5067 - val_accuracy: 0.4755\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.3446 - accuracy: 0.8948 - val_loss: 1.6475 - val_accuracy: 0.4921\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 45s 70ms/step - loss: 0.3052 - accuracy: 0.9123 - val_loss: 1.6755 - val_accuracy: 0.4738\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 46s 72ms/step - loss: 0.2713 - accuracy: 0.9221 - val_loss: 1.6897 - val_accuracy: 0.4895\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 43s 67ms/step - loss: 0.2435 - accuracy: 0.9363 - val_loss: 1.8666 - val_accuracy: 0.4895\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 44s 69ms/step - loss: 0.2200 - accuracy: 0.9427 - val_loss: 1.8464 - val_accuracy: 0.4869\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 52s 80ms/step - loss: 0.1868 - accuracy: 0.9568 - val_loss: 1.9274 - val_accuracy: 0.4825\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 47s 73ms/step - loss: 0.1634 - accuracy: 0.9655 - val_loss: 1.9993 - val_accuracy: 0.4607\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.1382 - accuracy: 0.9745 - val_loss: 2.0838 - val_accuracy: 0.4554\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.1186 - accuracy: 0.9798 - val_loss: 2.2163 - val_accuracy: 0.4615\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 47s 73ms/step - loss: 0.1160 - accuracy: 0.9772 - val_loss: 2.2009 - val_accuracy: 0.4755\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 2.2009 - accuracy: 0.4755\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 53s 83ms/step - loss: 1.5246 - accuracy: 0.3164 - val_loss: 1.4639 - val_accuracy: 0.3412\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 48s 75ms/step - loss: 1.3745 - accuracy: 0.4063 - val_loss: 1.4152 - val_accuracy: 0.3885\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 54s 84ms/step - loss: 1.2852 - accuracy: 0.4528 - val_loss: 1.3513 - val_accuracy: 0.4138\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 53s 82ms/step - loss: 1.2113 - accuracy: 0.4960 - val_loss: 1.3360 - val_accuracy: 0.4094\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 36s 55ms/step - loss: 1.1503 - accuracy: 0.5306 - val_loss: 1.3345 - val_accuracy: 0.4304\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 52s 80ms/step - loss: 1.0874 - accuracy: 0.5616 - val_loss: 1.3424 - val_accuracy: 0.4366\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 52s 81ms/step - loss: 1.0297 - accuracy: 0.5903 - val_loss: 1.3018 - val_accuracy: 0.4453\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 50s 77ms/step - loss: 0.9676 - accuracy: 0.6190 - val_loss: 1.2972 - val_accuracy: 0.4654\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 54s 84ms/step - loss: 0.9100 - accuracy: 0.6471 - val_loss: 1.3398 - val_accuracy: 0.4611\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 52s 80ms/step - loss: 0.8572 - accuracy: 0.6777 - val_loss: 1.3220 - val_accuracy: 0.4392\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 51s 79ms/step - loss: 0.8030 - accuracy: 0.6991 - val_loss: 1.3497 - val_accuracy: 0.4628\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 54s 84ms/step - loss: 0.7489 - accuracy: 0.7223 - val_loss: 1.3482 - val_accuracy: 0.4654\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 50s 77ms/step - loss: 0.6978 - accuracy: 0.7462 - val_loss: 1.3884 - val_accuracy: 0.4663\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 53s 83ms/step - loss: 0.6464 - accuracy: 0.7712 - val_loss: 1.4114 - val_accuracy: 0.4716\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 52s 81ms/step - loss: 0.6009 - accuracy: 0.7882 - val_loss: 1.4060 - val_accuracy: 0.4663\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 37s 57ms/step - loss: 0.5520 - accuracy: 0.8081 - val_loss: 1.4590 - val_accuracy: 0.4716\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 49s 77ms/step - loss: 0.5075 - accuracy: 0.8255 - val_loss: 1.5447 - val_accuracy: 0.4593\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 48s 74ms/step - loss: 0.4638 - accuracy: 0.8442 - val_loss: 1.6006 - val_accuracy: 0.4707\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 50s 77ms/step - loss: 0.4239 - accuracy: 0.8617 - val_loss: 1.6249 - val_accuracy: 0.4777\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 52s 80ms/step - loss: 0.3814 - accuracy: 0.8800 - val_loss: 1.8612 - val_accuracy: 0.4366\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 51s 79ms/step - loss: 0.3459 - accuracy: 0.8965 - val_loss: 1.7106 - val_accuracy: 0.4724\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/644 [==============================] - 43s 67ms/step - loss: 0.3049 - accuracy: 0.9111 - val_loss: 1.7982 - val_accuracy: 0.4812\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 45s 69ms/step - loss: 0.2689 - accuracy: 0.9278 - val_loss: 1.8490 - val_accuracy: 0.4646\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 48s 74ms/step - loss: 0.2391 - accuracy: 0.9377 - val_loss: 1.9312 - val_accuracy: 0.4777\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.2053 - accuracy: 0.9513 - val_loss: 1.9979 - val_accuracy: 0.4707\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 51s 79ms/step - loss: 0.1781 - accuracy: 0.9601 - val_loss: 2.0971 - val_accuracy: 0.4724\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 47s 73ms/step - loss: 0.1511 - accuracy: 0.9717 - val_loss: 2.1541 - val_accuracy: 0.4707\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.1298 - accuracy: 0.9770 - val_loss: 2.3389 - val_accuracy: 0.4654\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.1147 - accuracy: 0.9815 - val_loss: 2.4599 - val_accuracy: 0.4602\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 35s 55ms/step - loss: 0.1014 - accuracy: 0.9844 - val_loss: 2.4749 - val_accuracy: 0.4716\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 2.4749 - accuracy: 0.4716\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 48s 74ms/step - loss: 1.5224 - accuracy: 0.3162 - val_loss: 1.4470 - val_accuracy: 0.3902\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 44s 69ms/step - loss: 1.3605 - accuracy: 0.4144 - val_loss: 1.3753 - val_accuracy: 0.4068\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 54s 83ms/step - loss: 1.2671 - accuracy: 0.4645 - val_loss: 1.3791 - val_accuracy: 0.4112\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 52s 81ms/step - loss: 1.1987 - accuracy: 0.5035 - val_loss: 1.3391 - val_accuracy: 0.4392\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 48s 74ms/step - loss: 1.1309 - accuracy: 0.5431 - val_loss: 1.3061 - val_accuracy: 0.4444\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 49s 77ms/step - loss: 1.0702 - accuracy: 0.5704 - val_loss: 1.3137 - val_accuracy: 0.4549\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 52s 80ms/step - loss: 1.0089 - accuracy: 0.6022 - val_loss: 1.3112 - val_accuracy: 0.4506\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 48s 75ms/step - loss: 0.9536 - accuracy: 0.6220 - val_loss: 1.3061 - val_accuracy: 0.4733\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 48s 74ms/step - loss: 0.8953 - accuracy: 0.6600 - val_loss: 1.3350 - val_accuracy: 0.4733\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 43s 67ms/step - loss: 0.8371 - accuracy: 0.6830 - val_loss: 1.3214 - val_accuracy: 0.4803\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.7877 - accuracy: 0.7045 - val_loss: 1.3664 - val_accuracy: 0.4716\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 49s 76ms/step - loss: 0.7346 - accuracy: 0.7347 - val_loss: 1.3811 - val_accuracy: 0.4821\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 52s 81ms/step - loss: 0.6828 - accuracy: 0.7557 - val_loss: 1.3552 - val_accuracy: 0.4873\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 49s 76ms/step - loss: 0.6326 - accuracy: 0.7741 - val_loss: 1.3720 - val_accuracy: 0.4917\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 49s 77ms/step - loss: 0.5865 - accuracy: 0.7962 - val_loss: 1.4019 - val_accuracy: 0.5013\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 48s 74ms/step - loss: 0.5431 - accuracy: 0.8117 - val_loss: 1.4332 - val_accuracy: 0.5066\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.4951 - accuracy: 0.8330 - val_loss: 1.4707 - val_accuracy: 0.4987\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 51s 79ms/step - loss: 0.4578 - accuracy: 0.8476 - val_loss: 1.5342 - val_accuracy: 0.4934\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 50s 77ms/step - loss: 0.4054 - accuracy: 0.8740 - val_loss: 1.5657 - val_accuracy: 0.5013\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 51s 79ms/step - loss: 0.3705 - accuracy: 0.8861 - val_loss: 1.5775 - val_accuracy: 0.5092\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 53s 83ms/step - loss: 0.3304 - accuracy: 0.9016 - val_loss: 1.6460 - val_accuracy: 0.5136\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 49s 76ms/step - loss: 0.2946 - accuracy: 0.9129 - val_loss: 1.6893 - val_accuracy: 0.4996\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 52s 81ms/step - loss: 0.2621 - accuracy: 0.9297 - val_loss: 1.7304 - val_accuracy: 0.5022\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 47s 73ms/step - loss: 0.2255 - accuracy: 0.9460 - val_loss: 1.8125 - val_accuracy: 0.5057\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 51s 80ms/step - loss: 0.1994 - accuracy: 0.9521 - val_loss: 1.8488 - val_accuracy: 0.5101\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 53s 82ms/step - loss: 0.1666 - accuracy: 0.9660 - val_loss: 1.9812 - val_accuracy: 0.5022\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 51s 78ms/step - loss: 0.1426 - accuracy: 0.9734 - val_loss: 2.0746 - val_accuracy: 0.4934\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 49s 75ms/step - loss: 0.1235 - accuracy: 0.9804 - val_loss: 2.1298 - val_accuracy: 0.4943\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 47s 73ms/step - loss: 0.1034 - accuracy: 0.9841 - val_loss: 2.2437 - val_accuracy: 0.5004\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 50s 78ms/step - loss: 0.0927 - accuracy: 0.9850 - val_loss: 2.3019 - val_accuracy: 0.5048\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 2.3019 - accuracy: 0.5048\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 54s 84ms/step - loss: 1.5192 - accuracy: 0.3224 - val_loss: 1.4218 - val_accuracy: 0.3535\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 54s 83ms/step - loss: 1.3623 - accuracy: 0.4188 - val_loss: 1.3789 - val_accuracy: 0.3937\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 42s 65ms/step - loss: 1.2752 - accuracy: 0.4660 - val_loss: 1.3339 - val_accuracy: 0.4296\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 1.1972 - accuracy: 0.5063 - val_loss: 1.3097 - val_accuracy: 0.4418\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 1.1317 - accuracy: 0.5396 - val_loss: 1.3048 - val_accuracy: 0.4497\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 35s 54ms/step - loss: 1.0742 - accuracy: 0.5694 - val_loss: 1.2948 - val_accuracy: 0.4541\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 48s 75ms/step - loss: 1.0112 - accuracy: 0.6022 - val_loss: 1.2745 - val_accuracy: 0.4689\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.9520 - accuracy: 0.6293 - val_loss: 1.3173 - val_accuracy: 0.4471\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 0.8961 - accuracy: 0.6551 - val_loss: 1.2911 - val_accuracy: 0.4908\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.8366 - accuracy: 0.6828 - val_loss: 1.3125 - val_accuracy: 0.4549\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.7820 - accuracy: 0.7097 - val_loss: 1.3198 - val_accuracy: 0.4698\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.7329 - accuracy: 0.7268 - val_loss: 1.3227 - val_accuracy: 0.4777\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.6859 - accuracy: 0.7505 - val_loss: 1.3563 - val_accuracy: 0.4716\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.6290 - accuracy: 0.7742 - val_loss: 1.3828 - val_accuracy: 0.4864\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.5760 - accuracy: 0.8004 - val_loss: 1.4389 - val_accuracy: 0.4689\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.5339 - accuracy: 0.8162 - val_loss: 1.4740 - val_accuracy: 0.4786\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/644 [==============================] - 30s 46ms/step - loss: 0.4820 - accuracy: 0.8380 - val_loss: 1.5026 - val_accuracy: 0.4786\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.4377 - accuracy: 0.8578 - val_loss: 1.5326 - val_accuracy: 0.4838\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.3977 - accuracy: 0.8743 - val_loss: 1.6187 - val_accuracy: 0.4698\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.3543 - accuracy: 0.8928 - val_loss: 1.6624 - val_accuracy: 0.4794\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.3238 - accuracy: 0.9047 - val_loss: 1.7122 - val_accuracy: 0.4864\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 31s 47ms/step - loss: 0.2856 - accuracy: 0.9150 - val_loss: 1.7841 - val_accuracy: 0.4803\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.2444 - accuracy: 0.9372 - val_loss: 1.8313 - val_accuracy: 0.4724\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 27s 43ms/step - loss: 0.2183 - accuracy: 0.9457 - val_loss: 1.8679 - val_accuracy: 0.4978\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 28s 43ms/step - loss: 0.1890 - accuracy: 0.9557 - val_loss: 1.9372 - val_accuracy: 0.4777\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.1640 - accuracy: 0.9658 - val_loss: 2.0643 - val_accuracy: 0.4899\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.1430 - accuracy: 0.9707 - val_loss: 2.1418 - val_accuracy: 0.4891\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.1156 - accuracy: 0.9817 - val_loss: 2.2540 - val_accuracy: 0.4873\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.0983 - accuracy: 0.9861 - val_loss: 2.3588 - val_accuracy: 0.4917\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.0816 - accuracy: 0.9913 - val_loss: 2.4479 - val_accuracy: 0.4803\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 2.4479 - accuracy: 0.4803\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 1.5230 - accuracy: 0.3199 - val_loss: 1.4553 - val_accuracy: 0.3692\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.3706 - accuracy: 0.4086 - val_loss: 1.3816 - val_accuracy: 0.4191\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.2846 - accuracy: 0.4569 - val_loss: 1.3392 - val_accuracy: 0.4208\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.2140 - accuracy: 0.4980 - val_loss: 1.3132 - val_accuracy: 0.4374\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.1516 - accuracy: 0.5288 - val_loss: 1.3155 - val_accuracy: 0.4497\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 31s 47ms/step - loss: 1.0901 - accuracy: 0.5612 - val_loss: 1.2655 - val_accuracy: 0.4514\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 1.0314 - accuracy: 0.5897 - val_loss: 1.2730 - val_accuracy: 0.4689\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 27s 42ms/step - loss: 0.9754 - accuracy: 0.6188 - val_loss: 1.2715 - val_accuracy: 0.4654\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.9210 - accuracy: 0.6388 - val_loss: 1.2697 - val_accuracy: 0.4672\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.8681 - accuracy: 0.6685 - val_loss: 1.2863 - val_accuracy: 0.4803\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.8118 - accuracy: 0.6909 - val_loss: 1.2964 - val_accuracy: 0.4934\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.7618 - accuracy: 0.7199 - val_loss: 1.2921 - val_accuracy: 0.4926\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.7057 - accuracy: 0.7416 - val_loss: 1.3262 - val_accuracy: 0.4856\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.6558 - accuracy: 0.7670 - val_loss: 1.3306 - val_accuracy: 0.4882\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.6053 - accuracy: 0.7892 - val_loss: 1.3488 - val_accuracy: 0.4908\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.5570 - accuracy: 0.8134 - val_loss: 1.3671 - val_accuracy: 0.5039\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.5115 - accuracy: 0.8314 - val_loss: 1.4004 - val_accuracy: 0.4926\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.4694 - accuracy: 0.8485 - val_loss: 1.4350 - val_accuracy: 0.4882\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.4229 - accuracy: 0.8673 - val_loss: 1.5057 - val_accuracy: 0.4943\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.3842 - accuracy: 0.8823 - val_loss: 1.5732 - val_accuracy: 0.4882\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.3444 - accuracy: 0.8983 - val_loss: 1.6067 - val_accuracy: 0.4803\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.3082 - accuracy: 0.9164 - val_loss: 1.6915 - val_accuracy: 0.4759\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.2703 - accuracy: 0.9301 - val_loss: 1.7369 - val_accuracy: 0.4821\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.2350 - accuracy: 0.9432 - val_loss: 1.7609 - val_accuracy: 0.4961\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.2082 - accuracy: 0.9497 - val_loss: 1.9275 - val_accuracy: 0.4812\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.1785 - accuracy: 0.9606 - val_loss: 2.0082 - val_accuracy: 0.4742\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.1550 - accuracy: 0.9690 - val_loss: 2.0919 - val_accuracy: 0.4847\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.1315 - accuracy: 0.9753 - val_loss: 2.1334 - val_accuracy: 0.4777\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.1115 - accuracy: 0.9830 - val_loss: 2.2292 - val_accuracy: 0.4794\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.0969 - accuracy: 0.9858 - val_loss: 2.3397 - val_accuracy: 0.4786\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2.3397 - accuracy: 0.4786\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 29s 44ms/step - loss: 1.5258 - accuracy: 0.3123 - val_loss: 1.4494 - val_accuracy: 0.3736\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 29s 44ms/step - loss: 1.3687 - accuracy: 0.4101 - val_loss: 1.3984 - val_accuracy: 0.4121\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 29s 44ms/step - loss: 1.2780 - accuracy: 0.4631 - val_loss: 1.3431 - val_accuracy: 0.4348\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 1.2009 - accuracy: 0.5018 - val_loss: 1.3217 - val_accuracy: 0.4567\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 1.1313 - accuracy: 0.5384 - val_loss: 1.3010 - val_accuracy: 0.4742\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 1.0652 - accuracy: 0.5699 - val_loss: 1.3096 - val_accuracy: 0.4637\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 29s 44ms/step - loss: 1.0044 - accuracy: 0.6053 - val_loss: 1.3021 - val_accuracy: 0.4873\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.9465 - accuracy: 0.6325 - val_loss: 1.2967 - val_accuracy: 0.4786\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 28s 44ms/step - loss: 0.8875 - accuracy: 0.6595 - val_loss: 1.3194 - val_accuracy: 0.4733\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 29s 44ms/step - loss: 0.8293 - accuracy: 0.6864 - val_loss: 1.3173 - val_accuracy: 0.4847\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.7775 - accuracy: 0.7057 - val_loss: 1.3406 - val_accuracy: 0.4672\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/644 [==============================] - 29s 45ms/step - loss: 0.7200 - accuracy: 0.7376 - val_loss: 1.3719 - val_accuracy: 0.4777\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 0.6698 - accuracy: 0.7581 - val_loss: 1.3810 - val_accuracy: 0.4829\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.6160 - accuracy: 0.7840 - val_loss: 1.4009 - val_accuracy: 0.4803\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 36s 56ms/step - loss: 0.5679 - accuracy: 0.8052 - val_loss: 1.4739 - val_accuracy: 0.4768\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 41s 64ms/step - loss: 0.5216 - accuracy: 0.8255 - val_loss: 1.4519 - val_accuracy: 0.4821\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.4726 - accuracy: 0.8475 - val_loss: 1.5285 - val_accuracy: 0.4689\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 27s 41ms/step - loss: 0.4277 - accuracy: 0.8642 - val_loss: 1.5906 - val_accuracy: 0.4672\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 29s 44ms/step - loss: 0.3826 - accuracy: 0.8834 - val_loss: 1.6605 - val_accuracy: 0.4733\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.3465 - accuracy: 0.8947 - val_loss: 1.6849 - val_accuracy: 0.4777\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.3113 - accuracy: 0.9085 - val_loss: 1.8026 - val_accuracy: 0.4628\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 31s 47ms/step - loss: 0.2704 - accuracy: 0.9268 - val_loss: 1.8329 - val_accuracy: 0.4751\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.2372 - accuracy: 0.9390 - val_loss: 1.9451 - val_accuracy: 0.4768\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.2041 - accuracy: 0.9493 - val_loss: 1.9617 - val_accuracy: 0.4733\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.1736 - accuracy: 0.9631 - val_loss: 2.0730 - val_accuracy: 0.4803\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.1536 - accuracy: 0.9673 - val_loss: 2.1195 - val_accuracy: 0.4794\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 0.1261 - accuracy: 0.9794 - val_loss: 2.3060 - val_accuracy: 0.4558\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 0.1062 - accuracy: 0.9848 - val_loss: 2.3217 - val_accuracy: 0.4812\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.0903 - accuracy: 0.9885 - val_loss: 2.4775 - val_accuracy: 0.4576\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.0728 - accuracy: 0.9931 - val_loss: 2.5321 - val_accuracy: 0.4716\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 2.5321 - accuracy: 0.4716\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 35s 55ms/step - loss: 1.5228 - accuracy: 0.3131 - val_loss: 1.4923 - val_accuracy: 0.3491\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 1.3656 - accuracy: 0.4158 - val_loss: 1.3904 - val_accuracy: 0.4094\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 1.2713 - accuracy: 0.4698 - val_loss: 1.3475 - val_accuracy: 0.4287\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 1.1999 - accuracy: 0.5073 - val_loss: 1.3046 - val_accuracy: 0.4541\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.1348 - accuracy: 0.5386 - val_loss: 1.3214 - val_accuracy: 0.4523\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 1.0747 - accuracy: 0.5653 - val_loss: 1.3171 - val_accuracy: 0.4637\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 1.0178 - accuracy: 0.5985 - val_loss: 1.2746 - val_accuracy: 0.4724\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.9586 - accuracy: 0.6194 - val_loss: 1.3130 - val_accuracy: 0.4777\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.9037 - accuracy: 0.6475 - val_loss: 1.3027 - val_accuracy: 0.4672\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.8469 - accuracy: 0.6790 - val_loss: 1.2797 - val_accuracy: 0.4794\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 35s 54ms/step - loss: 0.7927 - accuracy: 0.7045 - val_loss: 1.3407 - val_accuracy: 0.4742\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.7432 - accuracy: 0.7236 - val_loss: 1.3102 - val_accuracy: 0.4847\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.6887 - accuracy: 0.7482 - val_loss: 1.3374 - val_accuracy: 0.4803\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.6379 - accuracy: 0.7725 - val_loss: 1.3451 - val_accuracy: 0.4847\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.5857 - accuracy: 0.7921 - val_loss: 1.3840 - val_accuracy: 0.4829\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.5340 - accuracy: 0.8166 - val_loss: 1.4295 - val_accuracy: 0.4812\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.4890 - accuracy: 0.8358 - val_loss: 1.4935 - val_accuracy: 0.4803\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.4451 - accuracy: 0.8514 - val_loss: 1.5149 - val_accuracy: 0.4847\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.3999 - accuracy: 0.8690 - val_loss: 1.5620 - val_accuracy: 0.4777\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.3560 - accuracy: 0.8908 - val_loss: 1.6405 - val_accuracy: 0.4742\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.3198 - accuracy: 0.9065 - val_loss: 1.6628 - val_accuracy: 0.4838\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 37s 58ms/step - loss: 0.2783 - accuracy: 0.9259 - val_loss: 1.7186 - val_accuracy: 0.4873\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 35s 54ms/step - loss: 0.2471 - accuracy: 0.9334 - val_loss: 1.7844 - val_accuracy: 0.4768\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 36s 55ms/step - loss: 0.2111 - accuracy: 0.9527 - val_loss: 2.0150 - val_accuracy: 0.4497\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 35s 55ms/step - loss: 0.1828 - accuracy: 0.9609 - val_loss: 1.9589 - val_accuracy: 0.4733\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 39s 61ms/step - loss: 0.1571 - accuracy: 0.9689 - val_loss: 2.0339 - val_accuracy: 0.4751\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.1290 - accuracy: 0.9780 - val_loss: 2.0797 - val_accuracy: 0.4856\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 0.1105 - accuracy: 0.9847 - val_loss: 2.1844 - val_accuracy: 0.4794\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.0997 - accuracy: 0.9866 - val_loss: 2.3477 - val_accuracy: 0.4891\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.0794 - accuracy: 0.9910 - val_loss: 2.3308 - val_accuracy: 0.4891\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 2.3308 - accuracy: 0.4891\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 1.5288 - accuracy: 0.3121 - val_loss: 1.4067 - val_accuracy: 0.3928\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 1.3747 - accuracy: 0.4081 - val_loss: 1.3233 - val_accuracy: 0.4339\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 1.2850 - accuracy: 0.4518 - val_loss: 1.2897 - val_accuracy: 0.4523\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 1.2142 - accuracy: 0.4961 - val_loss: 1.2850 - val_accuracy: 0.4567\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 1.1500 - accuracy: 0.5283 - val_loss: 1.2376 - val_accuracy: 0.4689\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 1.0932 - accuracy: 0.5595 - val_loss: 1.2326 - val_accuracy: 0.4689\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/644 [==============================] - 33s 50ms/step - loss: 1.0290 - accuracy: 0.5949 - val_loss: 1.2336 - val_accuracy: 0.4864\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.9707 - accuracy: 0.6202 - val_loss: 1.2117 - val_accuracy: 0.4969\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 34s 54ms/step - loss: 0.9110 - accuracy: 0.6505 - val_loss: 1.2349 - val_accuracy: 0.4908\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.8589 - accuracy: 0.6690 - val_loss: 1.2090 - val_accuracy: 0.5109\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 0.8043 - accuracy: 0.6962 - val_loss: 1.2233 - val_accuracy: 0.5057\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.7481 - accuracy: 0.7188 - val_loss: 1.2280 - val_accuracy: 0.5066\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.6956 - accuracy: 0.7442 - val_loss: 1.2606 - val_accuracy: 0.5214\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.6471 - accuracy: 0.7640 - val_loss: 1.2560 - val_accuracy: 0.4987\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.5939 - accuracy: 0.7909 - val_loss: 1.3091 - val_accuracy: 0.4987\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.5451 - accuracy: 0.8130 - val_loss: 1.3364 - val_accuracy: 0.4996\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.5008 - accuracy: 0.8268 - val_loss: 1.3404 - val_accuracy: 0.4934\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.4527 - accuracy: 0.8523 - val_loss: 1.4087 - val_accuracy: 0.4882\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.4174 - accuracy: 0.8698 - val_loss: 1.4417 - val_accuracy: 0.4952\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.3738 - accuracy: 0.8840 - val_loss: 1.4937 - val_accuracy: 0.4943\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 28s 43ms/step - loss: 0.3320 - accuracy: 0.9023 - val_loss: 1.5298 - val_accuracy: 0.4978\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.2959 - accuracy: 0.9165 - val_loss: 1.5904 - val_accuracy: 0.4891\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.2606 - accuracy: 0.9303 - val_loss: 1.6457 - val_accuracy: 0.4891\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.2288 - accuracy: 0.9412 - val_loss: 1.7330 - val_accuracy: 0.4899\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.1984 - accuracy: 0.9547 - val_loss: 1.7846 - val_accuracy: 0.4812\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.1677 - accuracy: 0.9647 - val_loss: 1.8544 - val_accuracy: 0.4934\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.1502 - accuracy: 0.9713 - val_loss: 1.9167 - val_accuracy: 0.5013\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.1244 - accuracy: 0.9776 - val_loss: 2.0610 - val_accuracy: 0.4961\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.0998 - accuracy: 0.9864 - val_loss: 2.1458 - val_accuracy: 0.4681\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 0.0860 - accuracy: 0.9894 - val_loss: 2.1804 - val_accuracy: 0.4856\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 2.1804 - accuracy: 0.4856\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(np.unique(epoch_label))\n",
    "for train_index, test_index in strat_kfold.split(epoch_data, epoch_label):\n",
    "    train_data, test_data = epoch_data[train_index], epoch_data[test_index]\n",
    "    train_labels, test_labels = epoch_label[train_index], epoch_label[test_index]\n",
    "    train_data = tf.expand_dims(train_data, axis = -1)\n",
    "    test_data = tf.expand_dims(test_data, axis = -1)\n",
    "    train_labels = tf.keras.utils.to_categorical(train_labels, num_classes = n_classes)\n",
    "    test_labels = tf.keras.utils.to_categorical(test_labels, num_classes = n_classes)\n",
    "    \n",
    "    input_shape = (train_data.shape[1], train_data.shape[2], train_data.shape[3])\n",
    "    model = create_cnn(input_shape = input_shape)\n",
    "    history = model.fit(train_data, train_labels, epochs = 30, batch_size = 16, \n",
    "                        validation_data = (test_data, test_labels))\n",
    "    _, acc = model.evaluate(test_data, test_labels)\n",
    "    predictions = model.predict(test_data)\n",
    "    predictions = np.array([np.argmax(prediction) for prediction in predictions])\n",
    "    real_labels = np.array([np.argmax(label) for label in test_labels])\n",
    "    acc_scores.append(acc)\n",
    "    prec_scores.append(precision_score(predictions, real_labels, average = 'weighted'))\n",
    "    rec_scores.append(recall_score(predictions, real_labels, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "644/644 [==============================] - 26s 41ms/step - loss: 1.5254 - accuracy: 0.3258 - val_loss: 1.4010 - val_accuracy: 0.3864\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 26s 40ms/step - loss: 1.3450 - accuracy: 0.4261 - val_loss: 1.3383 - val_accuracy: 0.4170\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 1.2494 - accuracy: 0.4828 - val_loss: 1.2865 - val_accuracy: 0.4344\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.1788 - accuracy: 0.5164 - val_loss: 1.2852 - val_accuracy: 0.4502\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.1119 - accuracy: 0.5509 - val_loss: 1.2604 - val_accuracy: 0.4729\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 1.0517 - accuracy: 0.5784 - val_loss: 1.2567 - val_accuracy: 0.4773\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.9931 - accuracy: 0.6131 - val_loss: 1.2600 - val_accuracy: 0.4773\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.9364 - accuracy: 0.6322 - val_loss: 1.2623 - val_accuracy: 0.4878\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.8801 - accuracy: 0.6621 - val_loss: 1.2591 - val_accuracy: 0.4860\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.8336 - accuracy: 0.6803 - val_loss: 1.2542 - val_accuracy: 0.5044\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.7758 - accuracy: 0.7048 - val_loss: 1.2925 - val_accuracy: 0.5149\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 0.7290 - accuracy: 0.7304 - val_loss: 1.2954 - val_accuracy: 0.4983\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.6781 - accuracy: 0.7538 - val_loss: 1.3111 - val_accuracy: 0.5070\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.6351 - accuracy: 0.7721 - val_loss: 1.3308 - val_accuracy: 0.5157\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.5900 - accuracy: 0.7890 - val_loss: 1.3751 - val_accuracy: 0.5026\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.5430 - accuracy: 0.8115 - val_loss: 1.3802 - val_accuracy: 0.4930\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.4978 - accuracy: 0.8275 - val_loss: 1.4105 - val_accuracy: 0.4965\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.4576 - accuracy: 0.8469 - val_loss: 1.4380 - val_accuracy: 0.5044\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.4096 - accuracy: 0.8671 - val_loss: 1.4909 - val_accuracy: 0.5044\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.3768 - accuracy: 0.8829 - val_loss: 1.5199 - val_accuracy: 0.5017\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.3364 - accuracy: 0.8970 - val_loss: 1.5800 - val_accuracy: 0.4948\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.2999 - accuracy: 0.9124 - val_loss: 1.6473 - val_accuracy: 0.4991\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.2727 - accuracy: 0.9239 - val_loss: 1.7386 - val_accuracy: 0.4965\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.2377 - accuracy: 0.9375 - val_loss: 1.7122 - val_accuracy: 0.5105\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.2023 - accuracy: 0.9533 - val_loss: 1.8155 - val_accuracy: 0.4825\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.1777 - accuracy: 0.9595 - val_loss: 1.8890 - val_accuracy: 0.4974\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.1543 - accuracy: 0.9681 - val_loss: 1.9593 - val_accuracy: 0.4939\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.1293 - accuracy: 0.9758 - val_loss: 2.1811 - val_accuracy: 0.4913\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.1153 - accuracy: 0.9812 - val_loss: 2.1021 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.0895 - accuracy: 0.9894 - val_loss: 2.2080 - val_accuracy: 0.4965\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 2.2080 - accuracy: 0.4965\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 37s 58ms/step - loss: 1.5166 - accuracy: 0.3313 - val_loss: 1.4453 - val_accuracy: 0.3802\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 38s 59ms/step - loss: 1.3382 - accuracy: 0.4273 - val_loss: 1.3789 - val_accuracy: 0.4143\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 36s 55ms/step - loss: 1.2415 - accuracy: 0.4836 - val_loss: 1.3497 - val_accuracy: 0.4248\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 41s 63ms/step - loss: 1.1731 - accuracy: 0.5199 - val_loss: 1.3425 - val_accuracy: 0.4379\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 1.1061 - accuracy: 0.5491 - val_loss: 1.3233 - val_accuracy: 0.4510\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.0431 - accuracy: 0.5829 - val_loss: 1.3182 - val_accuracy: 0.4545\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.9922 - accuracy: 0.6043 - val_loss: 1.3258 - val_accuracy: 0.4554\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 0.9358 - accuracy: 0.6412 - val_loss: 1.3130 - val_accuracy: 0.4659\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.8823 - accuracy: 0.6621 - val_loss: 1.3305 - val_accuracy: 0.4668\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.8262 - accuracy: 0.6909 - val_loss: 1.3558 - val_accuracy: 0.4572\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.7835 - accuracy: 0.7052 - val_loss: 1.3843 - val_accuracy: 0.4344\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.7299 - accuracy: 0.7331 - val_loss: 1.3424 - val_accuracy: 0.4755\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.6851 - accuracy: 0.7469 - val_loss: 1.3669 - val_accuracy: 0.4598\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 0.6299 - accuracy: 0.7781 - val_loss: 1.3833 - val_accuracy: 0.4712\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.5893 - accuracy: 0.7926 - val_loss: 1.4520 - val_accuracy: 0.4633\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.5460 - accuracy: 0.8111 - val_loss: 1.4604 - val_accuracy: 0.4712\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.4979 - accuracy: 0.8317 - val_loss: 1.4731 - val_accuracy: 0.4703\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 39s 60ms/step - loss: 0.4607 - accuracy: 0.8476 - val_loss: 1.6161 - val_accuracy: 0.4615\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.4168 - accuracy: 0.8657 - val_loss: 1.5236 - val_accuracy: 0.4965\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 37s 57ms/step - loss: 0.3774 - accuracy: 0.8824 - val_loss: 1.5908 - val_accuracy: 0.4948\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 35s 54ms/step - loss: 0.3382 - accuracy: 0.9009 - val_loss: 1.5910 - val_accuracy: 0.4886\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 41s 64ms/step - loss: 0.3024 - accuracy: 0.9134 - val_loss: 1.6587 - val_accuracy: 0.4834\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.2642 - accuracy: 0.9312 - val_loss: 1.7098 - val_accuracy: 0.4939\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 0.2333 - accuracy: 0.9402 - val_loss: 1.8259 - val_accuracy: 0.4816\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.2021 - accuracy: 0.9519 - val_loss: 1.8719 - val_accuracy: 0.4904\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.1755 - accuracy: 0.9626 - val_loss: 1.9207 - val_accuracy: 0.4904\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/644 [==============================] - 31s 48ms/step - loss: 0.1514 - accuracy: 0.9715 - val_loss: 2.0032 - val_accuracy: 0.4747\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.1357 - accuracy: 0.9732 - val_loss: 2.0579 - val_accuracy: 0.4799\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.1110 - accuracy: 0.9850 - val_loss: 2.1170 - val_accuracy: 0.4869\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 31s 47ms/step - loss: 0.0909 - accuracy: 0.9879 - val_loss: 2.2895 - val_accuracy: 0.4720\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 2.2895 - accuracy: 0.4720\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 1.5208 - accuracy: 0.3277 - val_loss: 1.3924 - val_accuracy: 0.3899\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.3461 - accuracy: 0.4336 - val_loss: 1.3218 - val_accuracy: 0.4073\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.2512 - accuracy: 0.4810 - val_loss: 1.2882 - val_accuracy: 0.4344\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.1745 - accuracy: 0.5185 - val_loss: 1.2646 - val_accuracy: 0.4554\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 1.1140 - accuracy: 0.5544 - val_loss: 1.2649 - val_accuracy: 0.4449\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 42s 65ms/step - loss: 1.0506 - accuracy: 0.5861 - val_loss: 1.2512 - val_accuracy: 0.4615\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 36s 56ms/step - loss: 0.9966 - accuracy: 0.6114 - val_loss: 1.2548 - val_accuracy: 0.4773\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 37s 57ms/step - loss: 0.9421 - accuracy: 0.6383 - val_loss: 1.2502 - val_accuracy: 0.4773\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.8875 - accuracy: 0.6658 - val_loss: 1.2477 - val_accuracy: 0.4738\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 40s 63ms/step - loss: 0.8362 - accuracy: 0.6857 - val_loss: 1.2402 - val_accuracy: 0.4878\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.7822 - accuracy: 0.7091 - val_loss: 1.2457 - val_accuracy: 0.4939\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.7301 - accuracy: 0.7311 - val_loss: 1.2675 - val_accuracy: 0.4913\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.6860 - accuracy: 0.7542 - val_loss: 1.3477 - val_accuracy: 0.4956\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.6390 - accuracy: 0.7741 - val_loss: 1.3342 - val_accuracy: 0.4904\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.5904 - accuracy: 0.7951 - val_loss: 1.3455 - val_accuracy: 0.4983\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.5422 - accuracy: 0.8161 - val_loss: 1.3646 - val_accuracy: 0.4834\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.5018 - accuracy: 0.8313 - val_loss: 1.4395 - val_accuracy: 0.5044\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.4513 - accuracy: 0.8535 - val_loss: 1.4042 - val_accuracy: 0.5070\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.4146 - accuracy: 0.8657 - val_loss: 1.4818 - val_accuracy: 0.4939\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.3777 - accuracy: 0.8823 - val_loss: 1.4694 - val_accuracy: 0.5052\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 31s 47ms/step - loss: 0.3353 - accuracy: 0.8997 - val_loss: 1.5846 - val_accuracy: 0.4983\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 0.3084 - accuracy: 0.9128 - val_loss: 1.6004 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 0.2624 - accuracy: 0.9303 - val_loss: 1.6165 - val_accuracy: 0.5140\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.2315 - accuracy: 0.9421 - val_loss: 1.7034 - val_accuracy: 0.5166\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.2009 - accuracy: 0.9517 - val_loss: 1.7648 - val_accuracy: 0.4991\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.1738 - accuracy: 0.9626 - val_loss: 1.8072 - val_accuracy: 0.5175\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.1491 - accuracy: 0.9704 - val_loss: 1.8365 - val_accuracy: 0.5192\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.1250 - accuracy: 0.9797 - val_loss: 1.9769 - val_accuracy: 0.4991\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.1090 - accuracy: 0.9838 - val_loss: 2.0206 - val_accuracy: 0.5061\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.0833 - accuracy: 0.9916 - val_loss: 2.1063 - val_accuracy: 0.5149\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 2.1063 - accuracy: 0.5149\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.5178 - accuracy: 0.3315 - val_loss: 1.4342 - val_accuracy: 0.3640\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.3419 - accuracy: 0.4327 - val_loss: 1.3949 - val_accuracy: 0.4024\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 1.2465 - accuracy: 0.4837 - val_loss: 1.3492 - val_accuracy: 0.4173\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 1.1689 - accuracy: 0.5201 - val_loss: 1.3156 - val_accuracy: 0.4392\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.1065 - accuracy: 0.5563 - val_loss: 1.3237 - val_accuracy: 0.4409\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 1.0461 - accuracy: 0.5800 - val_loss: 1.3135 - val_accuracy: 0.4523\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.9893 - accuracy: 0.6118 - val_loss: 1.2934 - val_accuracy: 0.4646\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.9382 - accuracy: 0.6389 - val_loss: 1.2877 - val_accuracy: 0.4698\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.8815 - accuracy: 0.6611 - val_loss: 1.2982 - val_accuracy: 0.4742\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.8306 - accuracy: 0.6877 - val_loss: 1.3294 - val_accuracy: 0.4619\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.7774 - accuracy: 0.7108 - val_loss: 1.3107 - val_accuracy: 0.4768\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.7239 - accuracy: 0.7332 - val_loss: 1.3386 - val_accuracy: 0.4777\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.6779 - accuracy: 0.7486 - val_loss: 1.3244 - val_accuracy: 0.4926\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.6256 - accuracy: 0.7777 - val_loss: 1.3854 - val_accuracy: 0.4759\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.5799 - accuracy: 0.7931 - val_loss: 1.4044 - val_accuracy: 0.4838\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 35s 54ms/step - loss: 0.5298 - accuracy: 0.8177 - val_loss: 1.5052 - val_accuracy: 0.4768\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 0.4825 - accuracy: 0.8409 - val_loss: 1.4717 - val_accuracy: 0.4882\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.4423 - accuracy: 0.8567 - val_loss: 1.4865 - val_accuracy: 0.4821\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.2853 - accuracy: 0.9198 - val_loss: 1.7070 - val_accuracy: 0.4996\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.2470 - accuracy: 0.9343 - val_loss: 1.7604 - val_accuracy: 0.4943\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.2130 - accuracy: 0.9483 - val_loss: 1.8150 - val_accuracy: 0.4917\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/644 [==============================] - 32s 50ms/step - loss: 0.1180 - accuracy: 0.9805 - val_loss: 2.2039 - val_accuracy: 0.4873\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.1019 - accuracy: 0.9860 - val_loss: 2.2906 - val_accuracy: 0.4864\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.0815 - accuracy: 0.9904 - val_loss: 2.2739 - val_accuracy: 0.5039\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 2.2739 - accuracy: 0.5039\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 1.5177 - accuracy: 0.3268 - val_loss: 1.4353 - val_accuracy: 0.3762\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 1.3443 - accuracy: 0.4225 - val_loss: 1.3796 - val_accuracy: 0.3885\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.2444 - accuracy: 0.4805 - val_loss: 1.3685 - val_accuracy: 0.4156\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 1.1038 - accuracy: 0.5538 - val_loss: 1.3150 - val_accuracy: 0.4558\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 1.0414 - accuracy: 0.5839 - val_loss: 1.3286 - val_accuracy: 0.4497\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 35s 54ms/step - loss: 0.9864 - accuracy: 0.6084 - val_loss: 1.3002 - val_accuracy: 0.4716\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 38s 59ms/step - loss: 0.9267 - accuracy: 0.6386 - val_loss: 1.2976 - val_accuracy: 0.4724\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 36s 56ms/step - loss: 0.8748 - accuracy: 0.6686 - val_loss: 1.3100 - val_accuracy: 0.4751\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 37s 57ms/step - loss: 0.8219 - accuracy: 0.6867 - val_loss: 1.3097 - val_accuracy: 0.4934\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 36s 56ms/step - loss: 0.7714 - accuracy: 0.7095 - val_loss: 1.3634 - val_accuracy: 0.4768\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 37s 57ms/step - loss: 0.7190 - accuracy: 0.7352 - val_loss: 1.3660 - val_accuracy: 0.4821\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 38s 59ms/step - loss: 0.6740 - accuracy: 0.7521 - val_loss: 1.3664 - val_accuracy: 0.5057\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 37s 57ms/step - loss: 0.6226 - accuracy: 0.7774 - val_loss: 1.4067 - val_accuracy: 0.5083\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 36s 56ms/step - loss: 0.5778 - accuracy: 0.7969 - val_loss: 1.4045 - val_accuracy: 0.4961\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 37s 57ms/step - loss: 0.5335 - accuracy: 0.8145 - val_loss: 1.4180 - val_accuracy: 0.5004\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 37s 57ms/step - loss: 0.4848 - accuracy: 0.8360 - val_loss: 1.4379 - val_accuracy: 0.4987\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 36s 55ms/step - loss: 0.4458 - accuracy: 0.8513 - val_loss: 1.5180 - val_accuracy: 0.4996\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 38s 59ms/step - loss: 0.4067 - accuracy: 0.8699 - val_loss: 1.5266 - val_accuracy: 0.5109\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 38s 59ms/step - loss: 0.3636 - accuracy: 0.8898 - val_loss: 1.5532 - val_accuracy: 0.5162\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 39s 60ms/step - loss: 0.3269 - accuracy: 0.9019 - val_loss: 1.6145 - val_accuracy: 0.5048\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 40s 62ms/step - loss: 0.2945 - accuracy: 0.9176 - val_loss: 1.6139 - val_accuracy: 0.5074\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 40s 62ms/step - loss: 0.2607 - accuracy: 0.9291 - val_loss: 1.6921 - val_accuracy: 0.5144\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.2256 - accuracy: 0.9440 - val_loss: 1.7631 - val_accuracy: 0.5074\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.1933 - accuracy: 0.9564 - val_loss: 1.8950 - val_accuracy: 0.5083\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.1711 - accuracy: 0.9624 - val_loss: 1.8498 - val_accuracy: 0.5066\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.1445 - accuracy: 0.9731 - val_loss: 1.9442 - val_accuracy: 0.5118\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.1201 - accuracy: 0.9818 - val_loss: 2.0079 - val_accuracy: 0.5039\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.1027 - accuracy: 0.9856 - val_loss: 2.1208 - val_accuracy: 0.4952\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 0.0846 - accuracy: 0.9902 - val_loss: 2.2501 - val_accuracy: 0.5092\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 2.2501 - accuracy: 0.5092\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 1.5171 - accuracy: 0.3203 - val_loss: 1.4145 - val_accuracy: 0.3841\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 1.3428 - accuracy: 0.4341 - val_loss: 1.3426 - val_accuracy: 0.4191\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 1.2512 - accuracy: 0.4806 - val_loss: 1.3063 - val_accuracy: 0.4418\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 1.1782 - accuracy: 0.5176 - val_loss: 1.3130 - val_accuracy: 0.4304\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.1112 - accuracy: 0.5569 - val_loss: 1.2863 - val_accuracy: 0.4654\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 1.0485 - accuracy: 0.5782 - val_loss: 1.2937 - val_accuracy: 0.4506\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.9929 - accuracy: 0.6142 - val_loss: 1.2554 - val_accuracy: 0.4803\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.9346 - accuracy: 0.6424 - val_loss: 1.2698 - val_accuracy: 0.4794\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.8779 - accuracy: 0.6656 - val_loss: 1.2811 - val_accuracy: 0.4838\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.8224 - accuracy: 0.6893 - val_loss: 1.3232 - val_accuracy: 0.4768\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.7699 - accuracy: 0.7118 - val_loss: 1.3082 - val_accuracy: 0.4759\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.7207 - accuracy: 0.7380 - val_loss: 1.3363 - val_accuracy: 0.4873\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 35s 54ms/step - loss: 0.6731 - accuracy: 0.7587 - val_loss: 1.3543 - val_accuracy: 0.4759\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.6227 - accuracy: 0.7809 - val_loss: 1.3385 - val_accuracy: 0.4978\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 29s 44ms/step - loss: 0.5805 - accuracy: 0.7979 - val_loss: 1.3406 - val_accuracy: 0.4856\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.5306 - accuracy: 0.8199 - val_loss: 1.4286 - val_accuracy: 0.4899\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 28s 44ms/step - loss: 0.4945 - accuracy: 0.8300 - val_loss: 1.4337 - val_accuracy: 0.4943\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 28s 43ms/step - loss: 0.4429 - accuracy: 0.8547 - val_loss: 1.4891 - val_accuracy: 0.4838\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 29s 44ms/step - loss: 0.4027 - accuracy: 0.8728 - val_loss: 1.5110 - val_accuracy: 0.4952\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.3626 - accuracy: 0.8881 - val_loss: 1.5901 - val_accuracy: 0.4794\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.3236 - accuracy: 0.9031 - val_loss: 1.6317 - val_accuracy: 0.4847\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.2890 - accuracy: 0.9166 - val_loss: 1.6488 - val_accuracy: 0.4943\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.2603 - accuracy: 0.9279 - val_loss: 1.7732 - val_accuracy: 0.4768\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/644 [==============================] - 30s 47ms/step - loss: 0.2250 - accuracy: 0.9433 - val_loss: 1.7893 - val_accuracy: 0.4838\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.1984 - accuracy: 0.9531 - val_loss: 1.8439 - val_accuracy: 0.4987\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.1718 - accuracy: 0.9601 - val_loss: 1.9542 - val_accuracy: 0.4943\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.1412 - accuracy: 0.9756 - val_loss: 2.0184 - val_accuracy: 0.4759\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.1289 - accuracy: 0.9761 - val_loss: 2.1037 - val_accuracy: 0.4908\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.1081 - accuracy: 0.9815 - val_loss: 2.1796 - val_accuracy: 0.4751\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 0.0882 - accuracy: 0.9887 - val_loss: 2.2105 - val_accuracy: 0.4794\n",
      "36/36 [==============================] - 1s 28ms/step - loss: 2.2105 - accuracy: 0.4794\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 1.5183 - accuracy: 0.3266 - val_loss: 1.4210 - val_accuracy: 0.3858\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.3433 - accuracy: 0.4289 - val_loss: 1.3579 - val_accuracy: 0.4086\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.2519 - accuracy: 0.4794 - val_loss: 1.3067 - val_accuracy: 0.4322\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 1.1761 - accuracy: 0.5176 - val_loss: 1.2814 - val_accuracy: 0.4488\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 1.1118 - accuracy: 0.5517 - val_loss: 1.2865 - val_accuracy: 0.4672\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 1.0459 - accuracy: 0.5858 - val_loss: 1.2880 - val_accuracy: 0.4584\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.9910 - accuracy: 0.6121 - val_loss: 1.2418 - val_accuracy: 0.4873\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.9343 - accuracy: 0.6359 - val_loss: 1.2389 - val_accuracy: 0.4829\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.8798 - accuracy: 0.6609 - val_loss: 1.2646 - val_accuracy: 0.4917\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 0.8256 - accuracy: 0.6896 - val_loss: 1.2627 - val_accuracy: 0.4794\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.7694 - accuracy: 0.7140 - val_loss: 1.2856 - val_accuracy: 0.5031\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.7224 - accuracy: 0.7321 - val_loss: 1.2514 - val_accuracy: 0.4969\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 0.6707 - accuracy: 0.7562 - val_loss: 1.2565 - val_accuracy: 0.4987\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 29s 44ms/step - loss: 0.6234 - accuracy: 0.7770 - val_loss: 1.3119 - val_accuracy: 0.5083\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.5764 - accuracy: 0.7976 - val_loss: 1.3347 - val_accuracy: 0.5066\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 0.5334 - accuracy: 0.8140 - val_loss: 1.3219 - val_accuracy: 0.4917\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.4900 - accuracy: 0.8343 - val_loss: 1.3665 - val_accuracy: 0.4969\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.4518 - accuracy: 0.8523 - val_loss: 1.4576 - val_accuracy: 0.4926\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 37s 58ms/step - loss: 0.4056 - accuracy: 0.8738 - val_loss: 1.4917 - val_accuracy: 0.4987\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.3673 - accuracy: 0.8865 - val_loss: 1.4817 - val_accuracy: 0.5074\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.3264 - accuracy: 0.8995 - val_loss: 1.5531 - val_accuracy: 0.5004\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.2923 - accuracy: 0.9161 - val_loss: 1.5698 - val_accuracy: 0.4996\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.2544 - accuracy: 0.9321 - val_loss: 1.6042 - val_accuracy: 0.5144\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.2210 - accuracy: 0.9466 - val_loss: 1.6591 - val_accuracy: 0.5144\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.1917 - accuracy: 0.9564 - val_loss: 1.7312 - val_accuracy: 0.5066\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.1706 - accuracy: 0.9625 - val_loss: 1.8161 - val_accuracy: 0.5039\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.1387 - accuracy: 0.9749 - val_loss: 1.8515 - val_accuracy: 0.5004\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.1147 - accuracy: 0.9812 - val_loss: 1.9681 - val_accuracy: 0.5057\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.1103 - accuracy: 0.9807 - val_loss: 2.0377 - val_accuracy: 0.5092\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 31s 47ms/step - loss: 0.0821 - accuracy: 0.9919 - val_loss: 2.1305 - val_accuracy: 0.5101\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 2.1305 - accuracy: 0.5101\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.5199 - accuracy: 0.3235 - val_loss: 1.4305 - val_accuracy: 0.3806\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.3435 - accuracy: 0.4281 - val_loss: 1.3544 - val_accuracy: 0.4479\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.2479 - accuracy: 0.4776 - val_loss: 1.3387 - val_accuracy: 0.4567\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 1.1706 - accuracy: 0.5216 - val_loss: 1.3382 - val_accuracy: 0.4602\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 1.1067 - accuracy: 0.5511 - val_loss: 1.3179 - val_accuracy: 0.4558\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 1.0476 - accuracy: 0.5830 - val_loss: 1.3287 - val_accuracy: 0.4558\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.9889 - accuracy: 0.6124 - val_loss: 1.2964 - val_accuracy: 0.4733\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.9333 - accuracy: 0.6359 - val_loss: 1.3093 - val_accuracy: 0.4628\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.8804 - accuracy: 0.6642 - val_loss: 1.3340 - val_accuracy: 0.4558\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.8252 - accuracy: 0.6900 - val_loss: 1.3201 - val_accuracy: 0.4707\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 29s 44ms/step - loss: 0.7723 - accuracy: 0.7134 - val_loss: 1.3169 - val_accuracy: 0.4663\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.7255 - accuracy: 0.7325 - val_loss: 1.3320 - val_accuracy: 0.4681\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.6774 - accuracy: 0.7489 - val_loss: 1.3441 - val_accuracy: 0.4768\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.6205 - accuracy: 0.7780 - val_loss: 1.4056 - val_accuracy: 0.4663\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.5796 - accuracy: 0.7933 - val_loss: 1.4516 - val_accuracy: 0.4689\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.5324 - accuracy: 0.8170 - val_loss: 1.4881 - val_accuracy: 0.4777\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.4898 - accuracy: 0.8331 - val_loss: 1.4970 - val_accuracy: 0.4672\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.4442 - accuracy: 0.8529 - val_loss: 1.5103 - val_accuracy: 0.4847\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/644 [==============================] - 31s 49ms/step - loss: 0.4044 - accuracy: 0.8697 - val_loss: 1.5684 - val_accuracy: 0.4471\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.3666 - accuracy: 0.8893 - val_loss: 1.6166 - val_accuracy: 0.4777\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.3272 - accuracy: 0.9025 - val_loss: 1.7069 - val_accuracy: 0.4567\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.2862 - accuracy: 0.9211 - val_loss: 1.7321 - val_accuracy: 0.4829\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.2526 - accuracy: 0.9313 - val_loss: 1.7644 - val_accuracy: 0.4786\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.2236 - accuracy: 0.9429 - val_loss: 1.8453 - val_accuracy: 0.4777\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.1905 - accuracy: 0.9576 - val_loss: 1.9672 - val_accuracy: 0.4821\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.1663 - accuracy: 0.9644 - val_loss: 1.9893 - val_accuracy: 0.4759\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.1440 - accuracy: 0.9702 - val_loss: 2.1025 - val_accuracy: 0.4541\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.1220 - accuracy: 0.9797 - val_loss: 2.1225 - val_accuracy: 0.4882\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 31s 49ms/step - loss: 0.0993 - accuracy: 0.9856 - val_loss: 2.2541 - val_accuracy: 0.4908\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.0905 - accuracy: 0.9896 - val_loss: 2.3785 - val_accuracy: 0.4663\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 2.3785 - accuracy: 0.4663\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.5161 - accuracy: 0.3317 - val_loss: 1.4662 - val_accuracy: 0.3596\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 1.3453 - accuracy: 0.4251 - val_loss: 1.3719 - val_accuracy: 0.4164\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 1.2463 - accuracy: 0.4779 - val_loss: 1.3377 - val_accuracy: 0.4488\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 31s 47ms/step - loss: 1.1790 - accuracy: 0.5212 - val_loss: 1.3014 - val_accuracy: 0.4584\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.1112 - accuracy: 0.5538 - val_loss: 1.2948 - val_accuracy: 0.4654\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 1.0505 - accuracy: 0.5806 - val_loss: 1.2752 - val_accuracy: 0.4856\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.9918 - accuracy: 0.6086 - val_loss: 1.2823 - val_accuracy: 0.4829\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.9385 - accuracy: 0.6342 - val_loss: 1.2617 - val_accuracy: 0.4926\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 0.8861 - accuracy: 0.6612 - val_loss: 1.2588 - val_accuracy: 0.4961\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.8288 - accuracy: 0.6889 - val_loss: 1.3221 - val_accuracy: 0.4716\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.7797 - accuracy: 0.7076 - val_loss: 1.2800 - val_accuracy: 0.5004\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.7218 - accuracy: 0.7346 - val_loss: 1.3584 - val_accuracy: 0.4812\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 29s 44ms/step - loss: 0.6747 - accuracy: 0.7581 - val_loss: 1.3013 - val_accuracy: 0.5101\n",
      "Epoch 14/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.6304 - accuracy: 0.7760 - val_loss: 1.3263 - val_accuracy: 0.5004\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.5787 - accuracy: 0.7969 - val_loss: 1.3316 - val_accuracy: 0.5022\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.5372 - accuracy: 0.8151 - val_loss: 1.4305 - val_accuracy: 0.4899\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.4917 - accuracy: 0.8328 - val_loss: 1.3941 - val_accuracy: 0.5092\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.4445 - accuracy: 0.8540 - val_loss: 1.4542 - val_accuracy: 0.5083\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.4069 - accuracy: 0.8698 - val_loss: 1.5081 - val_accuracy: 0.5004\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.3620 - accuracy: 0.8897 - val_loss: 1.5192 - val_accuracy: 0.5083\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.3330 - accuracy: 0.8984 - val_loss: 1.5720 - val_accuracy: 0.4847\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.2913 - accuracy: 0.9188 - val_loss: 1.6888 - val_accuracy: 0.4926\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 34s 52ms/step - loss: 0.2625 - accuracy: 0.9278 - val_loss: 1.6975 - val_accuracy: 0.5039\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 35s 54ms/step - loss: 0.2226 - accuracy: 0.9420 - val_loss: 1.7444 - val_accuracy: 0.5057\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 35s 54ms/step - loss: 0.1946 - accuracy: 0.9546 - val_loss: 1.8088 - val_accuracy: 0.4943\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.1698 - accuracy: 0.9609 - val_loss: 1.8599 - val_accuracy: 0.4996\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 0.1431 - accuracy: 0.9741 - val_loss: 1.9740 - val_accuracy: 0.4882\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.1186 - accuracy: 0.9820 - val_loss: 2.0507 - val_accuracy: 0.4891\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.1050 - accuracy: 0.9832 - val_loss: 2.1055 - val_accuracy: 0.4978\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 30s 46ms/step - loss: 0.0935 - accuracy: 0.9880 - val_loss: 2.1711 - val_accuracy: 0.4969\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 2.1711 - accuracy: 0.4969\n",
      "Epoch 1/30\n",
      "644/644 [==============================] - 28s 44ms/step - loss: 1.5222 - accuracy: 0.3247 - val_loss: 1.3843 - val_accuracy: 0.4121\n",
      "Epoch 2/30\n",
      "644/644 [==============================] - 28s 44ms/step - loss: 1.3474 - accuracy: 0.4226 - val_loss: 1.3213 - val_accuracy: 0.4427\n",
      "Epoch 3/30\n",
      "644/644 [==============================] - 28s 44ms/step - loss: 1.2571 - accuracy: 0.4756 - val_loss: 1.2944 - val_accuracy: 0.4549\n",
      "Epoch 4/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 1.1825 - accuracy: 0.5138 - val_loss: 1.2649 - val_accuracy: 0.4672\n",
      "Epoch 5/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 1.1177 - accuracy: 0.5506 - val_loss: 1.2476 - val_accuracy: 0.4707\n",
      "Epoch 6/30\n",
      "644/644 [==============================] - 34s 53ms/step - loss: 1.0544 - accuracy: 0.5823 - val_loss: 1.2453 - val_accuracy: 0.4628\n",
      "Epoch 7/30\n",
      "644/644 [==============================] - 38s 58ms/step - loss: 0.9978 - accuracy: 0.6079 - val_loss: 1.2238 - val_accuracy: 0.4856\n",
      "Epoch 8/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.9418 - accuracy: 0.6321 - val_loss: 1.2359 - val_accuracy: 0.4742\n",
      "Epoch 9/30\n",
      "644/644 [==============================] - 29s 46ms/step - loss: 0.8888 - accuracy: 0.6581 - val_loss: 1.2127 - val_accuracy: 0.5083\n",
      "Epoch 10/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.8396 - accuracy: 0.6843 - val_loss: 1.2245 - val_accuracy: 0.5066\n",
      "Epoch 11/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.7861 - accuracy: 0.7089 - val_loss: 1.2321 - val_accuracy: 0.5136\n",
      "Epoch 12/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.7345 - accuracy: 0.7261 - val_loss: 1.2551 - val_accuracy: 0.4943\n",
      "Epoch 13/30\n",
      "644/644 [==============================] - 29s 45ms/step - loss: 0.6853 - accuracy: 0.7493 - val_loss: 1.2948 - val_accuracy: 0.4934\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/644 [==============================] - 30s 46ms/step - loss: 0.6367 - accuracy: 0.7711 - val_loss: 1.2789 - val_accuracy: 0.5013\n",
      "Epoch 15/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.5970 - accuracy: 0.7938 - val_loss: 1.2866 - val_accuracy: 0.5188\n",
      "Epoch 16/30\n",
      "644/644 [==============================] - 31s 47ms/step - loss: 0.5428 - accuracy: 0.8131 - val_loss: 1.3127 - val_accuracy: 0.5057 0.5435 - accu\n",
      "Epoch 17/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.4989 - accuracy: 0.8306 - val_loss: 1.3184 - val_accuracy: 0.5223\n",
      "Epoch 18/30\n",
      "644/644 [==============================] - 30s 47ms/step - loss: 0.4566 - accuracy: 0.8521 - val_loss: 1.3765 - val_accuracy: 0.5101\n",
      "Epoch 19/30\n",
      "644/644 [==============================] - 36s 57ms/step - loss: 0.4225 - accuracy: 0.8603 - val_loss: 1.3729 - val_accuracy: 0.5153\n",
      "Epoch 20/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.3792 - accuracy: 0.8833 - val_loss: 1.4195 - val_accuracy: 0.5153\n",
      "Epoch 21/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.3342 - accuracy: 0.9025 - val_loss: 1.4867 - val_accuracy: 0.5092\n",
      "Epoch 22/30\n",
      "644/644 [==============================] - 31s 48ms/step - loss: 0.2997 - accuracy: 0.9139 - val_loss: 1.5174 - val_accuracy: 0.5206\n",
      "Epoch 23/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.2638 - accuracy: 0.9284 - val_loss: 1.5668 - val_accuracy: 0.5092\n",
      "Epoch 24/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.2357 - accuracy: 0.9391 - val_loss: 1.6559 - val_accuracy: 0.5197\n",
      "Epoch 25/30\n",
      "644/644 [==============================] - 33s 52ms/step - loss: 0.2020 - accuracy: 0.9511 - val_loss: 1.6767 - val_accuracy: 0.5074\n",
      "Epoch 26/30\n",
      "644/644 [==============================] - 32s 49ms/step - loss: 0.1777 - accuracy: 0.9598 - val_loss: 1.7861 - val_accuracy: 0.5188\n",
      "Epoch 27/30\n",
      "644/644 [==============================] - 32s 50ms/step - loss: 0.1531 - accuracy: 0.9677 - val_loss: 1.7991 - val_accuracy: 0.5162\n",
      "Epoch 28/30\n",
      "644/644 [==============================] - 28s 44ms/step - loss: 0.1223 - accuracy: 0.9810 - val_loss: 1.9018 - val_accuracy: 0.5197\n",
      "Epoch 29/30\n",
      "644/644 [==============================] - 28s 44ms/step - loss: 0.1097 - accuracy: 0.9824 - val_loss: 1.9702 - val_accuracy: 0.5118\n",
      "Epoch 30/30\n",
      "644/644 [==============================] - 28s 43ms/step - loss: 0.0863 - accuracy: 0.9910 - val_loss: 2.0142 - val_accuracy: 0.5118\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 2.0142 - accuracy: 0.5118\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(np.unique(epoch_label))\n",
    "for train_index, test_index in strat_kfold.split(epoch_data, epoch_label):\n",
    "    train_data, test_data = epoch_data[train_index], epoch_data[test_index]\n",
    "    train_labels, test_labels = epoch_label[train_index], epoch_label[test_index]\n",
    "    train_data = tf.expand_dims(train_data, axis = -1)\n",
    "    test_data = tf.expand_dims(test_data, axis = -1)\n",
    "    train_labels = tf.keras.utils.to_categorical(train_labels, num_classes = n_classes)\n",
    "    test_labels = tf.keras.utils.to_categorical(test_labels, num_classes = n_classes)\n",
    "    \n",
    "    input_shape = (train_data.shape[1], train_data.shape[2], train_data.shape[3])\n",
    "    model = create_cnn(input_shape = input_shape)\n",
    "    history = model.fit(train_data, train_labels, epochs = 30, batch_size = 16, \n",
    "                        validation_data = (test_data, test_labels))\n",
    "    _, acc = model.evaluate(test_data, test_labels)\n",
    "    predictions = model.predict(test_data)\n",
    "    predictions = np.array([np.argmax(prediction) for prediction in predictions])\n",
    "    real_labels = np.array([np.argmax(label) for label in test_labels])\n",
    "    acc_scores.append(acc)\n",
    "    prec_scores.append(precision_score(predictions, real_labels, average = 'weighted'))\n",
    "    rec_scores.append(recall_score(predictions, real_labels, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('iteration')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.savefig('Hasil/sliding_window.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.487762</td>\n",
       "      <td>0.492577</td>\n",
       "      <td>0.487762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.464161</td>\n",
       "      <td>0.467699</td>\n",
       "      <td>0.464161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.480708</td>\n",
       "      <td>0.475524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.471566</td>\n",
       "      <td>0.487981</td>\n",
       "      <td>0.471566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.504812</td>\n",
       "      <td>0.505925</td>\n",
       "      <td>0.504812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.480315</td>\n",
       "      <td>0.480286</td>\n",
       "      <td>0.480315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.478565</td>\n",
       "      <td>0.484918</td>\n",
       "      <td>0.478565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.471566</td>\n",
       "      <td>0.474893</td>\n",
       "      <td>0.471566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.489064</td>\n",
       "      <td>0.494944</td>\n",
       "      <td>0.489064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.485564</td>\n",
       "      <td>0.490589</td>\n",
       "      <td>0.485564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall\n",
       "0  0.487762   0.492577  0.487762\n",
       "1  0.464161   0.467699  0.464161\n",
       "2  0.475524   0.480708  0.475524\n",
       "3  0.471566   0.487981  0.471566\n",
       "4  0.504812   0.505925  0.504812\n",
       "5  0.480315   0.480286  0.480315\n",
       "6  0.478565   0.484918  0.478565\n",
       "7  0.471566   0.474893  0.471566\n",
       "8  0.489064   0.494944  0.489064\n",
       "9  0.485564   0.490589  0.485564"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Accuracy': acc_scores, 'Precision': prec_scores,\n",
    "                   'Recall': rec_scores})\n",
    "df\n",
    "# df.to_csv('Hasil/CV_SW_{}.csv'.format(subject_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.496504</td>\n",
       "      <td>0.499294</td>\n",
       "      <td>0.496503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.472028</td>\n",
       "      <td>0.482305</td>\n",
       "      <td>0.472028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.514860</td>\n",
       "      <td>0.515615</td>\n",
       "      <td>0.514860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.503937</td>\n",
       "      <td>0.503486</td>\n",
       "      <td>0.503937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.509186</td>\n",
       "      <td>0.529837</td>\n",
       "      <td>0.509186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.479440</td>\n",
       "      <td>0.480199</td>\n",
       "      <td>0.479440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.510061</td>\n",
       "      <td>0.518032</td>\n",
       "      <td>0.510061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.466317</td>\n",
       "      <td>0.466643</td>\n",
       "      <td>0.466317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.496938</td>\n",
       "      <td>0.495200</td>\n",
       "      <td>0.496938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.511811</td>\n",
       "      <td>0.519720</td>\n",
       "      <td>0.511811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall\n",
       "0  0.496504   0.499294  0.496503\n",
       "1  0.472028   0.482305  0.472028\n",
       "2  0.514860   0.515615  0.514860\n",
       "3  0.503937   0.503486  0.503937\n",
       "4  0.509186   0.529837  0.509186\n",
       "5  0.479440   0.480199  0.479440\n",
       "6  0.510061   0.518032  0.510061\n",
       "7  0.466317   0.466643  0.466317\n",
       "8  0.496938   0.495200  0.496938\n",
       "9  0.511811   0.519720  0.511811"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Accuracy': acc_scores, 'Precision': prec_scores,\n",
    "                   'Recall': rec_scores})\n",
    "df\n",
    "# df.to_csv('Hasil/CV_SW_{}.csv'.format(subject_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = ['thumb', 'index', 'middle', 'ring', 'pinky']\n",
    "cm = confusion_matrix(real_labels, predictions, normalize = 'true')\n",
    "df_cm = pd.DataFrame(cm, index = label, columns = label)\n",
    "plt.figure(figsize = (5, 5))\n",
    "sn.heatmap(df_cm, annot = True)\n",
    "# plt.savefig('Hasil/CM_{}_SW.png'.format(subject_name), facecolor = 'w', edgecolor = 'w')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
